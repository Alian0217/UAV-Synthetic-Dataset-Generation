"""
æ•°æ®é›†éªŒè¯å·¥å…·
éªŒè¯ç”Ÿæˆçš„æ•°æ®é›†å®Œæ•´æ€§å’Œè´¨é‡
"""

import os
import json
import cv2
import numpy as np

class DatasetValidator:
    """æ•°æ®é›†éªŒè¯å™¨"""
    
    def __init__(self, data_dir="generated_data"):
        self.data_dir = data_dir
        self.validation_results = {}
    
    def validate_all(self):
        """éªŒè¯æ•´ä¸ªæ•°æ®é›†"""
        print("ğŸ” å¼€å§‹éªŒè¯æ•°æ®é›†...")
        
        results = {
            'directory_structure': self.validate_directory_structure(),
            'image_files': self.validate_image_files(),
            'metadata_files': self.validate_metadata_files(),
            'annotation_files': self.validate_annotation_files(),
            'data_consistency': self.validate_data_consistency()
        }
        
        self.print_validation_summary(results)
        return results
    
    def validate_directory_structure(self):
        """éªŒè¯ç›®å½•ç»“æ„"""
        print("ğŸ“ éªŒè¯ç›®å½•ç»“æ„...")
        
        required_files = []
        for file in os.listdir(self.data_dir):
            if file.endswith('.png') or file.endswith('.json'):
                required_files.append(file)
        
        has_scene_images = any(f.startswith('scene_') and f.endswith('.png') and not f.startswith(('mask_', 'depth_')) for f in required_files)
        has_metadata = any(f.startswith('scene_') and f.endswith('.json') and 'annotations' not in f for f in required_files)
        has_annotations = any('annotations' in f for f in required_files)
        has_masks = any(f.startswith('mask_') for f in required_files)
        has_depth = any(f.startswith('depth_') for f in required_files)
        
        return {
            'status': has_scene_images and has_metadata and has_annotations,
            'details': {
                'scene_images': has_scene_images,
                'metadata': has_metadata,
                'annotations': has_annotations,
                'masks': has_masks,
                'depth_maps': has_depth,
                'total_files': len(required_files)
            }
        }
    
    def validate_image_files(self):
        """éªŒè¯å›¾åƒæ–‡ä»¶"""
        print("ğŸ–¼ï¸ éªŒè¯å›¾åƒæ–‡ä»¶...")
        
        image_files = [f for f in os.listdir(self.data_dir) 
                      if f.endswith('.png') and not f.startswith(('mask_', 'depth_'))]
        
        results = []
        for img_file in image_files:
            try:
                img_path = os.path.join(self.data_dir, img_file)
                img = cv2.imread(img_path)
                if img is not None:
                    results.append({
                        'file': img_file,
                        'status': 'âœ…',
                        'size': img.shape,
                        'channels': img.shape[2] if len(img.shape) > 2 else 1
                    })
                else:
                    results.append({
                        'file': img_file,
                        'status': 'âŒ',
                        'error': 'æ— æ³•è¯»å–å›¾åƒ'
                    })
            except Exception as e:
                results.append({
                    'file': img_file,
                    'status': 'âŒ',
                    'error': str(e)
                })
        
        valid_count = len([r for r in results if r['status'] == 'âœ…'])
        return {
            'status': valid_count == len(image_files),
            'details': results,
            'summary': f'{valid_count}/{len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶æœ‰æ•ˆ'
        }
    
    def validate_metadata_files(self):
        """éªŒè¯å…ƒæ•°æ®æ–‡ä»¶"""
        print("ğŸ“‹ éªŒè¯å…ƒæ•°æ®æ–‡ä»¶...")
        
        metadata_files = [f for f in os.listdir(self.data_dir) 
                         if f.endswith('.json') and 'annotations' not in f]
        
        results = []
        for meta_file in metadata_files:
            try:
                meta_path = os.path.join(self.data_dir, meta_file)
                with open(meta_path, 'r') as f:
                    metadata = json.load(f)
                
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_fields = ['scene_id', 'scene_type', 'camera_parameters', 'objects']
                has_required = all(field in metadata for field in required_fields)
                
                results.append({
                    'file': meta_file,
                    'status': 'âœ…' if has_required else 'âŒ',
                    'scene_id': metadata.get('scene_id', 'ç¼ºå¤±'),
                    'scene_type': metadata.get('scene_type', 'ç¼ºå¤±'),
                    'object_count': len(metadata.get('objects', [])),
                    'missing_fields': [f for f in required_fields if f not in metadata]
                })
            except Exception as e:
                results.append({
                    'file': meta_file,
                    'status': 'âŒ',
                    'error': str(e)
                })
        
        valid_count = len([r for r in results if r['status'] == 'âœ…'])
        return {
            'status': valid_count == len(metadata_files),
            'details': results,
            'summary': f'{valid_count}/{len(metadata_files)} ä¸ªå…ƒæ•°æ®æ–‡ä»¶æœ‰æ•ˆ'
        }
    
    def validate_annotation_files(self):
        """éªŒè¯æ ‡æ³¨æ–‡ä»¶"""
        print("ğŸ“ éªŒè¯æ ‡æ³¨æ–‡ä»¶...")
        
        annotation_files = [f for f in os.listdir(self.data_dir) if 'annotations' in f and f.endswith('.json')]
        
        results = []
        for ann_file in annotation_files:
            try:
                ann_path = os.path.join(self.data_dir, ann_file)
                with open(ann_path, 'r') as f:
                    annotations = json.load(f)
                
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                required_fields = ['image_file', 'bounding_boxes', 'camera_pose']
                has_required = all(field in annotations for field in required_fields)
                
                results.append({
                    'file': ann_file,
                    'status': 'âœ…' if has_required else 'âŒ',
                    'image_file': annotations.get('image_file', 'ç¼ºå¤±'),
                    'bbox_count': len(annotations.get('bounding_boxes', [])),
                    'missing_fields': [f for f in required_fields if f not in annotations]
                })
            except Exception as e:
                results.append({
                    'file': ann_file,
                    'status': 'âŒ',
                    'error': str(e)
                })
        
        valid_count = len([r for r in results if r['status'] == 'âœ…'])
        return {
            'status': valid_count == len(annotation_files),
            'details': results,
            'summary': f'{valid_count}/{len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶æœ‰æ•ˆ'
        }
    
    def validate_data_consistency(self):
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        print("ğŸ”— éªŒè¯æ•°æ®ä¸€è‡´æ€§...")
        
        # æ£€æŸ¥å›¾åƒå’Œå…ƒæ•°æ®çš„å¯¹åº”å…³ç³»
        scene_images = [f for f in os.listdir(self.data_dir) 
                       if f.startswith('scene_') and f.endswith('.png') and not f.startswith(('mask_', 'depth_'))]
        metadata_files = [f for f in os.listdir(self.data_dir) 
                         if f.startswith('scene_') and f.endswith('.json') and 'annotations' not in f]
        
        consistency_issues = []
        
        for img_file in scene_images:
            base_name = img_file.replace('.png', '')
            corresponding_meta = base_name + '.json'
            corresponding_ann = base_name + '_annotations.json'
            corresponding_mask = 'mask_' + img_file
            corresponding_depth = 'depth_' + img_file
            
            missing_files = []
            if corresponding_meta not in metadata_files:
                missing_files.append(corresponding_meta)
            if corresponding_ann not in os.listdir(self.data_dir):
                missing_files.append(corresponding_ann)
            if corresponding_mask not in os.listdir(self.data_dir):
                missing_files.append(corresponding_mask)
            if corresponding_depth not in os.listdir(self.data_dir):
                missing_files.append(corresponding_depth)
            
            if missing_files:
                consistency_issues.append({
                    'image': img_file,
                    'missing_files': missing_files
                })
        
        return {
            'status': len(consistency_issues) == 0,
            'details': consistency_issues,
            'summary': f'ä¸€è‡´æ€§æ£€æŸ¥: {len(consistency_issues)} ä¸ªé—®é¢˜' if consistency_issues else 'æ‰€æœ‰æ–‡ä»¶å¯¹åº”å…³ç³»æ­£ç¡®'
        }
    
    def print_validation_summary(self, results):
        """æ‰“å°éªŒè¯æ€»ç»“"""
        print("\n" + "="*60)
        print("                   æ•°æ®é›†éªŒè¯æ€»ç»“")
        print("="*60)
        
        all_passed = all(result['status'] for result in results.values())
        
        for check_name, result in results.items():
            status_icon = "âœ…" if result['status'] else "âŒ"
            print(f"{status_icon} {check_name}: {result['summary']}")
        
        print("\n" + "="*60)
        if all_passed:
            print("ğŸ‰ æ•°æ®é›†éªŒè¯é€šè¿‡ï¼æ‰€æœ‰æ£€æŸ¥é¡¹å‡æˆåŠŸã€‚")
        else:
            print("âš ï¸  æ•°æ®é›†å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šã€‚")
        
        return all_passed

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    validator = DatasetValidator()
    results = validator.validate_all()
    
    # ä¿å­˜éªŒè¯æŠ¥å‘Š
    report_path = "generated_data/validation_report.json"
    with open(report_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

if __name__ == "__main__":
    main()