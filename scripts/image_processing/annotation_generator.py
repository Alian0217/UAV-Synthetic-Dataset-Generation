"""
æ ‡æ³¨ç”Ÿæˆæ¨¡å—
ä½¿ç”¨ OpenCV ç”Ÿæˆåˆæˆæ•°æ®çš„æ ‡æ³¨
"""

import cv2
import numpy as np
import json
import os

class AnnotationGenerator:
    """æ ‡æ³¨ç”Ÿæˆå™¨"""
    
    def __init__(self):
        print("ğŸ–Šï¸ æ ‡æ³¨ç”Ÿæˆå™¨åˆå§‹åŒ–")
    
    def generate_annotations(self, image_path, metadata_path):
        """ä¸ºå›¾åƒç”Ÿæˆæ ‡æ³¨"""
        # è¯»å–å›¾åƒå’Œå…ƒæ•°æ®
        image = cv2.imread(image_path)
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        # ç”Ÿæˆåˆ†å‰²æ©ç 
        segmentation_mask = self._create_segmentation_mask(image, metadata)
        
        # ç”Ÿæˆè¾¹ç•Œæ¡†
        bounding_boxes = self._create_bounding_boxes(metadata)
        
        # ç”Ÿæˆæ·±åº¦å›¾ï¼ˆæ¨¡æ‹Ÿï¼‰
        depth_map = self._create_depth_map(image.shape, metadata)
        
        annotations = {
            'image_file': os.path.basename(image_path),
            'metadata_file': os.path.basename(metadata_path),
            'image_size': [image.shape[1], image.shape[0]],  # [width, height]
            'segmentation_mask': 'mask_' + os.path.basename(image_path),
            'bounding_boxes': bounding_boxes,
            'depth_map': 'depth_' + os.path.basename(image_path),
            'camera_pose': metadata['camera_parameters']
        }
        
        # ä¿å­˜æ ‡æ³¨æ–‡ä»¶
        annotation_path = image_path.replace('.png', '_annotations.json')
        with open(annotation_path, 'w') as f:
            json.dump(annotations, f, indent=2)
        
        # ä¿å­˜åˆ†å‰²æ©ç å’Œæ·±åº¦å›¾
        mask_path = image_path.replace('.png', '_mask.png')
        depth_path = image_path.replace('.png', '_depth.png')
        cv2.imwrite(mask_path, segmentation_mask)
        cv2.imwrite(depth_path, depth_map)
        
        print(f"âœ… æ ‡æ³¨ç”Ÿæˆå®Œæˆ: {annotation_path}")
        return annotations
    
    def _create_segmentation_mask(self, image, metadata):
        """åˆ›å»ºåˆ†å‰²æ©ç """
        height, width = image.shape[:2]
        mask = np.zeros((height, width), dtype=np.uint8)
        
        # æ ¹æ®å…ƒæ•°æ®åœ¨æ©ç ä¸Šæ ‡è®°ä¸åŒç‰©ä½“ç±»å‹
        for i, obj in enumerate(metadata['objects']):
            obj_type = obj['type']
            obj_value = self._get_object_class_value(obj_type)
            
            # ç®€åŒ–ï¼šåœ¨å›¾åƒä¸­å¿ƒåŒºåŸŸç»˜åˆ¶æ ‡è®°
            center_x, center_y = width // 2, height // 2
            obj_x = center_x + (i - len(metadata['objects'])//2) * 80
            obj_y = center_y
            
            if obj_type == 'building':
                cv2.rectangle(mask, (obj_x-30, obj_y-50), (obj_x+30, obj_y), obj_value, -1)
            elif obj_type == 'tree':
                cv2.circle(mask, (obj_x, obj_y), 25, obj_value, -1)
            else:
                cv2.rectangle(mask, (obj_x-20, obj_y-20), (obj_x+20, obj_y+20), obj_value, -1)
        
        return mask
    
    def _get_object_class_value(self, obj_type):
        """è·å–ç‰©ä½“ç±»å‹çš„åˆ†ç±»å€¼"""
        class_map = {
            'building': 1,
            'tree': 2,
            'obstacle': 3
        }
        return class_map.get(obj_type, 0)
    
    def _create_bounding_boxes(self, metadata):
        """åˆ›å»ºè¾¹ç•Œæ¡†æ ‡æ³¨"""
        bboxes = []
        
        for i, obj in enumerate(metadata['objects']):
            bbox = {
                'object_id': i,
                'class': obj['type'],
                'bbox': [  # [x, y, width, height] å½’ä¸€åŒ–åæ ‡
                    0.3 + (i * 0.1), 0.4, 0.1, 0.2
                ],
                'position': obj['position']
            }
            bboxes.append(bbox)
        
        return bboxes
    
    def _create_depth_map(self, image_shape, metadata):
        """åˆ›å»ºæ·±åº¦å›¾ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        height, width = image_shape[:2]
        depth_map = np.ones((height, width), dtype=np.uint8) * 128
        
        # æ ¹æ®ç‰©ä½“ä½ç½®æ·»åŠ æ·±åº¦å˜åŒ–
        for i, obj in enumerate(metadata['objects']):
            center_x, center_y = width // 2, height // 2
            obj_x = center_x + (i - len(metadata['objects'])//2) * 80
            
            # æ·±åº¦å€¼ä¸é«˜åº¦ç›¸å…³
            depth_value = max(50, min(200, 150 - i * 20))
            cv2.circle(depth_map, (obj_x, center_y), 40, depth_value, -1)
        
        return depth_map

def process_all_scenes():
    """å¤„ç†æ‰€æœ‰ç”Ÿæˆçš„åœºæ™¯"""
    data_dir = "generated_data"
    generator = AnnotationGenerator()
    
    processed_count = 0
    for file in os.listdir(data_dir):
        if file.endswith('.png') and not file.startswith(('mask_', 'depth_')):
            image_path = os.path.join(data_dir, file)
            metadata_path = image_path.replace('.png', '.json')
            
            if os.path.exists(metadata_path):
                generator.generate_annotations(image_path, metadata_path)
                processed_count += 1
    
    print(f"\nğŸ‰ æ ‡æ³¨å¤„ç†å®Œæˆ! å¤„ç†äº† {processed_count} ä¸ªåœºæ™¯")

if __name__ == "__main__":
    process_all_scenes()