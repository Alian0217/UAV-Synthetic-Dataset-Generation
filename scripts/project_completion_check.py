"""
UAV é¡¹ç›®å®Œæˆç¡®è®¤æ£€æŸ¥
ç¡®è®¤æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½éƒ½å·²å®ç°
"""

import os
import json
import cv2

def check_project_completion():
    print("ğŸš€ UAV Synthetic Dataset - é¡¹ç›®å®Œæˆç¡®è®¤")
    print("=" * 60)
    
    completion_status = {
        'environment': check_environment(),
        'project_structure': check_project_structure(),
        'core_functionality': check_core_functionality(),
        'data_generation': check_data_generation(),
        'documentation': check_documentation()
    }
    
    print_summary(completion_status)

def check_environment():
    """æ£€æŸ¥Pythonç¯å¢ƒ"""
    print("\nğŸ Pythonç¯å¢ƒæ£€æŸ¥:")
    
    try:
        import cv2
        import numpy as np
        print("  âœ… OpenCV: å¯ç”¨")
        print("  âœ… NumPy: å¯ç”¨")
        return True
    except ImportError as e:
        print(f"  âŒ ç¯å¢ƒé—®é¢˜: {e}")
        return False

def check_project_structure():
    """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
    print("\nğŸ“ é¡¹ç›®ç»“æ„æ£€æŸ¥:")
    
    required_dirs = ['scripts', 'scripts/ue_control', 'scripts/image_processing', 'scripts/dataset_utils']
    required_files = [
        'scripts/data_pipeline.py',
        'scripts/image_processing/annotation_generator.py',
        'README.md',
        'requirements.txt'
    ]
    
    all_good = True
    
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            print(f"  âœ… ç›®å½•: {dir_path}")
        else:
            print(f"  âŒ ç¼ºå¤±ç›®å½•: {dir_path}")
            all_good = False
    
    for file_path in required_files:
        if os.path.exists(file_path):
            print(f"  âœ… æ–‡ä»¶: {file_path}")
        else:
            print(f"  âŒ ç¼ºå¤±æ–‡ä»¶: {file_path}")
            all_good = False
    
    return all_good

def check_core_functionality():
    """æ£€æŸ¥æ ¸å¿ƒåŠŸèƒ½"""
    print("\nğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ£€æŸ¥:")
    
    functionalities = [
        ("æ•°æ®æµæ°´çº¿", "scripts/data_pipeline.py", "ç”Ÿæˆåˆæˆåœºæ™¯"),
        ("æ ‡æ³¨ç”Ÿæˆå™¨", "scripts/image_processing/annotation_generator.py", "è‡ªåŠ¨ç”Ÿæˆæ ‡æ³¨"),
        ("éªŒè¯å·¥å…·", "scripts/dataset_utils/validate_dataset_fixed.py", "æ•°æ®è´¨é‡éªŒè¯")
    ]
    
    all_good = True
    
    for name, path, description in functionalities:
        if os.path.exists(path):
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦éç©º
            file_size = os.path.getsize(path)
            if file_size > 100:  # å¤§äº100å­—èŠ‚è®¤ä¸ºæ˜¯æœ‰å†…å®¹çš„æ–‡ä»¶
                print(f"  âœ… {name}: {description}")
            else:
                print(f"  âš ï¸  {name}: æ–‡ä»¶å†…å®¹å¯èƒ½ä¸å®Œæ•´")
                all_good = False
        else:
            print(f"  âŒ {name}: æ–‡ä»¶ä¸å­˜åœ¨")
            all_good = False
    
    return all_good

def check_data_generation():
    """æ£€æŸ¥æ•°æ®ç”Ÿæˆèƒ½åŠ›"""
    print("\nğŸ“Š æ•°æ®ç”Ÿæˆæ£€æŸ¥:")
    
    if not os.path.exists("generated_data"):
        print("  âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return False
    
    files = os.listdir("generated_data")
    
    # æ£€æŸ¥åœºæ™¯000çš„å®Œæ•´æ€§
    scene_000_files = [
        'scene_000.png',
        'scene_000.json', 
        'scene_000_annotations.json',
        'scene_000_mask.png',
        'scene_000_depth.png'
    ]
    
    missing_files = []
    for file in scene_000_files:
        if file in files:
            print(f"  âœ… {file}")
            
            # éªŒè¯æ–‡ä»¶å¯è¯»æ€§
            file_path = f"generated_data/{file}"
            if file.endswith('.png'):
                img = cv2.imread(file_path)
                if img is None:
                    print(f"     âš ï¸  è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ")
            elif file.endswith('.json'):
                try:
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                except:
                    print(f"     âš ï¸  è­¦å‘Š: JSONæ ¼å¼å¯èƒ½æœ‰é—®é¢˜")
        else:
            print(f"  âŒ {file}")
            missing_files.append(file)
    
    if missing_files:
        print(f"  âš ï¸  åœºæ™¯000ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    else:
        print("  âœ… åœºæ™¯000å®Œæ•´ - å¯ä»¥ç”¨äºæ¨¡å‹è®­ç»ƒ")
        return True

def check_documentation():
    """æ£€æŸ¥æ–‡æ¡£"""
    print("\nğŸ“š æ–‡æ¡£æ£€æŸ¥:")
    
    if os.path.exists("README.md"):
        file_size = os.path.getsize("README.md")
        if file_size > 500:
            print("  âœ… README.md: å®Œæ•´")
        else:
            print("  âš ï¸  README.md: å†…å®¹å¯èƒ½è¾ƒå°‘")
    else:
        print("  âŒ README.md: ç¼ºå¤±")
    
    # æ£€æŸ¥GitçŠ¶æ€
    if os.path.exists(".git"):
        print("  âœ… Gitç‰ˆæœ¬æ§åˆ¶: å·²åˆå§‹åŒ–")
    else:
        print("  âš ï¸  Gitç‰ˆæœ¬æ§åˆ¶: æœªåˆå§‹åŒ–")
    
    return True

def print_summary(status):
    """æ‰“å°æ€»ç»“"""
    print("\n" + "=" * 60)
    print("ğŸ¯ é¡¹ç›®å®Œæˆåº¦æ€»ç»“")
    print("=" * 60)
    
    total_checks = len(status)
    passed_checks = sum(1 for check_passed in status.values() if check_passed)
    
    for check_name, check_passed in status.items():
        icon = "âœ…" if check_passed else "âŒ"
        print(f"{icon} {check_name}: {'é€šè¿‡' if check_passed else 'æœªé€šè¿‡'}")
    
    completion_rate = (passed_checks / total_checks) * 100
    print(f"\nğŸ“ˆ æ€»ä½“å®Œæˆåº¦: {completion_rate:.1f}%")
    
    if completion_rate >= 90:
        print("ğŸ‰ é¡¹ç›®çŠ¶æ€: æˆåŠŸå®Œæˆ!")
        print("   æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å‡å·²å®ç°ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®é›†ã€‚")
    elif completion_rate >= 70:
        print("âœ… é¡¹ç›®çŠ¶æ€: åŸºæœ¬å®Œæˆ")
        print("   æ ¸å¿ƒåŠŸèƒ½å¯ç”¨ï¼Œå»ºè®®è¿›ä¸€æ­¥å®Œå–„æ–‡æ¡£å’Œæµ‹è¯•ã€‚")
    else:
        print("âš ï¸  é¡¹ç›®çŠ¶æ€: éœ€è¦æ›´å¤šå·¥ä½œ")
        print("   å»ºè®®ä¼˜å…ˆå®Œæˆç¼ºå¤±çš„æ ¸å¿ƒåŠŸèƒ½ã€‚")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    if status['data_generation']:
        print("   1. ç”Ÿæˆæ›´å¤šåœºæ™¯æ•°æ®")
        print("   2. å¼€å§‹æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
    else:
        print("   1. å®Œå–„æ•°æ®ç”ŸæˆåŠŸèƒ½")
        print("   2. ç¡®ä¿è‡³å°‘ä¸€ä¸ªå®Œæ•´åœºæ™¯")

if __name__ == "__main__":
    check_project_completion()